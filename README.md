# Multimodal Variational Autoencoder (MVAE)

## Overview

This repository contains an implementation of the Multimodal Variational Autoencoder (MVAE), a generative model introduced in the paper "Multimodal Generative Models for Scalable Weakly-Supervised Learning" by Mike Wu and Noah Goodman. This implementation is part of a machine learning class project conducted at TU Berlin.

The project focuses on exploring the MVAE's capability to efficiently learn joint representations from multiple modalities using a variational autoencoder approach. By implementing the methods proposed in the paper, we aim to gain insights into the effectiveness of MVAE in addressing challenges related to weakly-supervised learning and incomplete supervision.

## Getting Started

### Prerequisites

- Python (>=3.6)
- PyTorch
- Other dependencies...

### Installation

1. Clone the repository:

   ```bash
   git clone https://github.com/your-username/MVAE-project.git
   cd MVAE-project
   ```

2. Install the dependencies:

   ```bash
   pip install -r requirements.txt
   ```

### Usage

1. Train the MVAE model:

   ```bash
   python main.py
   ```